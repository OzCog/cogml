/**
 * Foundation Layer: Hardware Matrix Configuration Header
 * Auto-generated hardware configuration for cognitive kernel tensor operations
 * 
 * This file defines hardware-specific optimizations for the OpenCog
 * Foundation Layer cognitive kernel implementation.
 */

#ifndef HARDWARE_MATRIX_CONFIG_H
#define HARDWARE_MATRIX_CONFIG_H

// ========================================================================
// Architecture Configuration
// ========================================================================

#define TARGET_ARCHITECTURE "@TARGET_ARCH@"
#define SYSTEM_ARCH_X86_64    0
#define SYSTEM_ARCH_ARM64     1
#define SYSTEM_ARCH_RISCV64   2
#define SYSTEM_ARCH_GENERIC   3

#if defined(@TARGET_ARCH@_x86_64)
    #define CURRENT_ARCH SYSTEM_ARCH_X86_64
#elif defined(@TARGET_ARCH@_arm64)
    #define CURRENT_ARCH SYSTEM_ARCH_ARM64
#elif defined(@TARGET_ARCH@_riscv64)
    #define CURRENT_ARCH SYSTEM_ARCH_RISCV64
#else
    #define CURRENT_ARCH SYSTEM_ARCH_GENERIC
#endif

// ========================================================================
// Tensor SIMD Configuration
// ========================================================================

#define TENSOR_SIMD_ENABLED @TENSOR_SIMD_SUPPORT@
#define VECTOR_INSTRUCTION_SET "@VECTOR_INSTRUCTION_SET@"

#define TENSOR_BLOCK_SIZE @TENSOR_BLOCK_SIZE@
#define TENSOR_VECTOR_WIDTH @TENSOR_VECTOR_WIDTH@

// Vector instruction set definitions
#define VECTOR_SET_SCALAR  0
#define VECTOR_SET_AVX2    1
#define VECTOR_SET_AVX512  2
#define VECTOR_SET_NEON    3

#if defined(VECTOR_INSTRUCTION_SET_AVX512)
    #define CURRENT_VECTOR_SET VECTOR_SET_AVX512
    #include <immintrin.h>
    typedef __m512 tensor_vector_t;
#elif defined(VECTOR_INSTRUCTION_SET_AVX2)
    #define CURRENT_VECTOR_SET VECTOR_SET_AVX2
    #include <immintrin.h>
    typedef __m256 tensor_vector_t;
#elif defined(VECTOR_INSTRUCTION_SET_NEON)
    #define CURRENT_VECTOR_SET VECTOR_SET_NEON
    #include <arm_neon.h>
    typedef float32x4_t tensor_vector_t;
#else
    #define CURRENT_VECTOR_SET VECTOR_SET_SCALAR
    typedef float tensor_vector_t;
#endif

// ========================================================================
// Cache Configuration
// ========================================================================

#define L1_CACHE_SIZE @L1_CACHE_SIZE@
#define L2_CACHE_SIZE @L2_CACHE_SIZE@
#define L3_CACHE_SIZE @L3_CACHE_SIZE@

#define TENSOR_L1_TILE_SIZE @TENSOR_L1_TILE_SIZE@
#define TENSOR_L2_TILE_SIZE @TENSOR_L2_TILE_SIZE@
#define TENSOR_L3_TILE_SIZE @TENSOR_L3_TILE_SIZE@

// ========================================================================
// GPU Acceleration Configuration
// ========================================================================

#define TENSOR_CUDA_ENABLED @TENSOR_CUDA_SUPPORT@
#define TENSOR_OPENCL_ENABLED @TENSOR_OPENCL_SUPPORT@

#if TENSOR_CUDA_ENABLED
    #define CUDA_BLOCK_SIZE @CUDA_BLOCK_SIZE@
    #define CUDA_GRID_SIZE @CUDA_GRID_SIZE@
#endif

// ========================================================================
// GGML Integration Configuration
// ========================================================================

#define GGML_ENABLED @ENABLE_GGML@

#if GGML_ENABLED
    #define GGML_BACKEND "@GGML_BACKEND@"
    #define GGML_TENSOR_FORMATS "@GGML_TENSOR_FORMATS@"
    #define GGML_BLOCK_FORMATS "@GGML_BLOCK_FORMATS@"
    
    // GGML tensor type definitions
    typedef enum {
        GGML_TENSOR_FP32,
        GGML_TENSOR_FP16,
        GGML_TENSOR_INT8,
        GGML_TENSOR_Q4_0,
        GGML_TENSOR_Q4_1,
        GGML_TENSOR_Q5_0,
        GGML_TENSOR_Q5_1,
        GGML_TENSOR_Q8_0
    } ggml_tensor_type_t;
#endif

// ========================================================================
// Recursive Implementation Configuration
// ========================================================================

#define RECURSIVE_COGNITIVE_KERNEL 1
#define MAX_RECURSION_DEPTH @MAX_RECURSION_DEPTH@
#define STACK_SIZE_MB @STACK_SIZE_MB@

// Recursion safety macros
#define CHECK_RECURSION_DEPTH(current_depth) \
    do { \
        if ((current_depth) >= MAX_RECURSION_DEPTH) { \
            return false; /* or appropriate error handling */ \
        } \
    } while(0)

// ========================================================================
// Tensor Degrees of Freedom Configuration
// ========================================================================

#define SPATIAL_TENSOR_DIM @SPATIAL_TENSOR_DIM@
#define TEMPORAL_TENSOR_DIM @TEMPORAL_TENSOR_DIM@
#define SEMANTIC_TENSOR_DIM @SEMANTIC_TENSOR_DIM@
#define LOGICAL_TENSOR_DIM @LOGICAL_TENSOR_DIM@

// Tensor shape definitions for cognitive operations
typedef struct {
    float spatial[SPATIAL_TENSOR_DIM];      // 3D spatial coordinates
} spatial_tensor_t;

typedef struct {
    float temporal[TEMPORAL_TENSOR_DIM];    // Temporal sequence point
} temporal_tensor_t;

typedef struct {
    float semantic[SEMANTIC_TENSOR_DIM];    // Semantic embedding vector
} semantic_tensor_t;

typedef struct {
    float logical[LOGICAL_TENSOR_DIM];      // Logical inference state
} logical_tensor_t;

// Combined cognitive tensor for full degrees of freedom
typedef struct {
    spatial_tensor_t spatial;
    temporal_tensor_t temporal;
    semantic_tensor_t semantic;
    logical_tensor_t logical;
} cognitive_tensor_t;

// ========================================================================
// Performance Optimization Macros
// ========================================================================

// Branch prediction hints
#if defined(__GNUC__)
    #define LIKELY(x)   __builtin_expect(!!(x), 1)
    #define UNLIKELY(x) __builtin_expect(!!(x), 0)
#else
    #define LIKELY(x)   (x)
    #define UNLIKELY(x) (x)
#endif

// Memory prefetch hints
#if defined(__GNUC__)
    #define PREFETCH_READ(ptr)  __builtin_prefetch((ptr), 0, 3)
    #define PREFETCH_WRITE(ptr) __builtin_prefetch((ptr), 1, 3)
#else
    #define PREFETCH_READ(ptr)  ((void)0)
    #define PREFETCH_WRITE(ptr) ((void)0)
#endif

// Cache line alignment
#define CACHE_LINE_SIZE 64
#define CACHE_ALIGNED __attribute__((aligned(CACHE_LINE_SIZE)))

// ========================================================================
// Tensor Operation Function Pointers
// ========================================================================

// Function pointer types for hardware-optimized tensor operations
typedef void (*tensor_add_func_t)(const float* a, const float* b, float* result, size_t size);
typedef void (*tensor_mul_func_t)(const float* a, const float* b, float* result, size_t size);
typedef void (*tensor_dot_func_t)(const float* a, const float* b, float* result, size_t size);

// Hardware-specific tensor operation dispatch table
typedef struct {
    tensor_add_func_t add;
    tensor_mul_func_t mul;
    tensor_dot_func_t dot;
} tensor_ops_t;

// ========================================================================
// Hardware Matrix Capabilities
// ========================================================================

typedef struct {
    const char* architecture;
    bool simd_support;
    const char* vector_instruction_set;
    bool cuda_support;
    bool opencl_support;
    bool ggml_support;
    int max_recursion_depth;
    int tensor_block_size;
    int vector_width;
} hardware_capabilities_t;

// Global hardware capabilities (defined in implementation)
extern const hardware_capabilities_t g_hardware_caps;

// ========================================================================
// Utility Functions
// ========================================================================

#ifdef __cplusplus
extern "C" {
#endif

// Initialize hardware-specific optimizations
int init_hardware_matrix(void);

// Get optimal tensor operation functions for current hardware
const tensor_ops_t* get_tensor_ops(void);

// Hardware capability queries
bool has_simd_support(void);
bool has_gpu_acceleration(void);
bool has_ggml_support(void);
int get_optimal_block_size(size_t tensor_size);

#ifdef __cplusplus
}
#endif

#endif /* HARDWARE_MATRIX_CONFIG_H */