
Performance diary
-----------------

Below reports performance, measured on "fanny", a circa-2014 server.
All results by Linas.

3 July 2019
-----------
Modern version of guile, current atomspace.

Guile: guile (GNU Guile) 2.9.2.14-1fb399
Atomspace: git log
commit a015b988246cd042cba836b30e050032fd5feca3
    Merge: 978d997 e167406
    Author: Nil Geisweiller <ngeiswei@gmail.com>
    Date:   Tue Jul 2 13:01:36 2019 +0300

Not sure, I think the compiler was this (that's what it was in May...)
compiler: gcc version 6.3.0 (Debian 6.3.0-18+deb9u1) 6.3.0 20170516
glibc: ldconfig -V (Debian GLIBC 2.24-11+deb9u4) 2.24

Repeated testing. Run as "guile -l nano-en.scm".
Got this:

Elapsed: 124 secs Tot-cnt=152904 Avg=0.2153 secs/word Rate=1233.1 cnts/sec
Elapsed: 123 secs Tot-cnt=152904 Avg=0.2135 secs/word Rate=1243.1 cnts/sec
Elapsed: 128 secs Tot-cnt=152904 Avg=0.2222 secs/word Rate=1194.6 cnts/sec
Elapsed: 123 secs Tot-cnt=152904 Avg=0.2135 secs/word Rate=1243.1 cnts/sec
Elapsed: 126 secs Tot-cnt=152904 Avg=0.2188 secs/word Rate=1213.5 cnts/sec


As can be seen, there is relatively little variation, from run to run,
in the measured performance.

12 Dec 2019
-----------
Performance improves by a lot. But why? Going back to the above git
version, but with today's compiler, shows:

Elapsed: 87 secs Tot-cnt=152904 Avg=0.1510 secs/word Rate=1757.5 cnts/sec
Elapsed: 88 secs Tot-cnt=152904 Avg=0.1528 secs/word Rate=1737.5 cnts/sec
Elapsed: 89 secs Tot-cnt=152904 Avg=0.1545 secs/word Rate=1718.0 cnts/sec

Compare to today's git (and today's compilers, etc.), below, which runs
slightly slower (despite fixes to the AtomTable) (perhaps recent pattern
matcher mods slowed things down?). So conclude: **all** of the perf
improvement can be ascribed to either the compiler, or the different
glibc version (the `perf_events` tool suggests that a lot of CPU time,
about 16% of it, is spent in `std::__shared_ptr<opencog::Atom, etc`
and another 5% is in `std::_Rb_tree<opencog::Handle, etc.`) So this is
definitely a "wow" moment.

guile (GNU Guile) 2.9.2
gcc version 8.3.0 (Debian 8.3.0-6)
ldconfig (Debian GLIBC 2.28-10) 2.28
git commit f96a6c7bd0c3c41e06668b810193cad4d2d6dc4c

Three runs with *exactly* the same times:

Elapsed: 89 secs Tot-cnt=152904 Avg=0.1545 secs/word Rate=1718.0 cnts/sec
Elapsed: 89 secs Tot-cnt=152904 Avg=0.1545 secs/word Rate=1718.0 cnts/sec
Elapsed: 89 secs Tot-cnt=152904 Avg=0.1545 secs/word Rate=1718.0 cnts/sec

Again: with guile (GNU Guile) 2.9.7-dirty
Elapsed: 89 secs Tot-cnt=152904 Avg=0.1545 secs/word Rate=1718.0 cnts/sec

so no change at all for the newer guile version. Hmmm.

-------------
try this:
HUGETLB_MORECORE=yes LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libhugetlbfs.so.0 guile -l nano-en.scm

Wow! Even for this relatively small test, the difference is dramatic!
Elapsed: 72 secs Tot-cnt=152904 Avg= 0.125 secs/word Rate=2123.7 cnts/sec
Elapsed: 71 secs Tot-cnt=152904 Avg=0.1233 secs/word Rate=2153.6 cnts/sec
Elapsed: 70 secs Tot-cnt=152904 Avg=0.1215 secs/word Rate=2184.3 cnts/sec

-------------
And again: on Ubuntu 16.04 LTS:
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11)
ldconfig (Ubuntu GLIBC 2.23-0ubuntu11) 2.23
guile (GNU Guile) 2.9.2.36-89e28
atomspace git: 6904dc0c2f0d3b122d46d5b00a6d28a0f2bfa279 (6 Sept 2019)

Elapsed: 133 secs Tot-cnt=152904 Avg=0.2309 secs/word Rate=1149.7 cnts/sec
Elapsed: 134 secs Tot-cnt=152904 Avg=0.2326 secs/word Rate=1141.1 cnts/sec
Elapsed: 134 secs Tot-cnt=152904 Avg=0.2326 secs/word Rate=1141.1 cnts/sec

and again, with todays atomspace git:
git commit dc7bf87bdf51e0afd3a0870fd73f172bcd80239d

Elapsed: 124 secs Tot-cnt=152904 Avg=0.2153 secs/word Rate=1233.1 cnts/sec
Elapsed: 122 secs Tot-cnt=152904 Avg=0.2118 secs/word Rate=1253.3 cnts/sec
Elapsed: 122 secs Tot-cnt=152904 Avg=0.2118 secs/word Rate=1253.3 cnts/sec

Conclude: some atomspace changes made a difference. But also, the compiler
and/or glibc is making a huge difference.

5 Jan 2020
----------
After pull req opencog/atomspace#2464 which avoids some pointless
IncomingSet wasteage, I now measure (with hugetlb)

Elapsed: 60 secs Tot-cnt=152904 Avg=0.1042 secs/word Rate=2548.4 cnts/sec
Elapsed: 59 secs Tot-cnt=152904 Avg=0.1024 secs/word Rate=2591.6 cnts/sec
Elapsed: 59 secs Tot-cnt=152904 Avg=0.1024 secs/word Rate=2591.6 cnts/sec

Prior reesult for this was 72 secs (fanny, with hugetlb).

13 Jan 2020
-----------
After rework on direct upward moves, now hitting

Elapsed: 58 secs Tot-cnt=152904 Avg=0.1007 secs/word Rate=2636.3 cnts/sec

Disabling #define DEBUG in the pattern matcher takes us down one more
second:

Elapsed: 57 secs Tot-cnt=152904 Avg=0.0990 secs/word Rate=2682.5 cnts/sec

26 Oct 2021
-----------
Sanity check the latest code.

guile: guile (GNU Guile) 3.0.7.6-22120
/sbin/ldconfig -V: ldconfig (Debian GLIBC 2.31-13+deb11u2) 2.31
gcc (Debian 10.2.1-6) 10.2.1 20210110
git log:
commit b4502c84f516eb24f66d2848f4191cd24d47fb48
Merge: 348722a1c d9cfa8e6d
Author: Linas VepÅ¡tas <linasvepstas@gmail.com>
Date:   Tue Oct 26 15:38:02 2021 -0500

Without hugeTLB:
Elapsed: 94 secs Tot-cnt=152904 Avg=0.1632 secs/word Rate=1626.6 cnts/sec
Elapsed: 93 secs Tot-cnt=152904 Avg=0.1615 secs/word Rate=1644.1 cnts/sec

with HugeTLB:
Elapsed: 74 secs Tot-cnt=152904 Avg=0.1285 secs/word Rate=2066.3 cnts/sec
Elapsed: 72 secs Tot-cnt=152904 Avg= 0.125 secs/word Rate=2123.7 cnts/sec

Confusing. The scores are about where the Dec 2019 scores were.
What happened to the improvements noted above?

26 Oct 2021
-----------
Some nano-dot results (without HugeTLB):

dot-fake: Elapsed: 4.52 secs Avg=0.0078 secs/word Rate=127.48 words/sec
dot-simple: Elapsed: 4.71 secs Avg=0.0082 secs/word Rate=122.35 words/sec
dot-identical: Elapsed: 5.15 secs Avg=0.0089 secs/word Rate=111.84 words/sec
dot-lambda: Elapsed: 5.43 secs Avg=0.0094 secs/word Rate=106.01 words/sec
dot-choice: Elapsed: 7.91 secs Avg=0.0137 secs/word Rate=72.849 words/sec
dot-mashup: Elapsed: 8.35 secs Avg=0.0145 secs/word Rate=68.951 words/sec
dot-matrix: Elapsed: 4.32 secs Avg=0.0075 secs/word Rate=133.41 words/sec

And again, with HugeTLB:
dot-simple: Elapsed: 4.97 secs Avg=0.0086 secs/word Rate=115.85 words/sec
dot-identical: Elapsed: 5.33 secs Avg=0.0093 secs/word Rate=108.05 words/sec
dot-lambda: Elapsed: 5.50 secs Avg=0.0095 secs/word Rate=104.74 words/sec
dot-choice: Elapsed: 7.74 secs Avg=0.0134 secs/word Rate=74.371 words/sec
dot-mashup: Elapsed: 8.15 secs Avg=0.0141 secs/word Rate=70.689 words/sec
dot-matrix: Elapsed: 4.85 secs Avg=0.0084 secs/word Rate=118.85 words/sec

Wow. So that's actually slower. And it's best out of three, and HugeTLB
is consistently slower. How is that possible? Well, apparently, we're
not missing anything here. Curious.

Also curious: The use of the AtomSpace AccumulateLink machinery is
actually slower than letting guile do all the work. Surprising, but
maybe not that surprising, for two reasons:
1) We use the pattern matcher to find the basis elements to feed
   to the matrix routines that guile runs; so there is a common cost
   that both styles share: the overhead of the patten matcher itself.
2) guile code is byte-compiled. Thus, although we splurge with scheme
   lists in the matrix code, causing a lot of malloc/free under the
   covers, we also splurge with FloatValues in the AtomSpace
   Instantiator code, which, although small, do have to be malloced,
   reference-counted and freed. So, not unlike splurging the scheme
   lists.

So ... that's interesting.

Here is the performance, using `add-tuple-math` instead of `add-fast-math`
in `cosine.scm` circa line 155 (i.e. the old style). Three runs:

dot-matrix: Elapsed: 12.55 secs Avg=0.0218 secs/word Rate=45.892 words/sec
dot-matrix: Elapsed: 12.29 secs Avg=0.0213 secs/word Rate=46.882 words/sec
dot-matrix: Elapsed: 12.62 secs Avg=0.0219 secs/word Rate=45.628 words/sec

So, less than half the speed. Converting to use the pattern matcher does
make a big difference. I wonder what would happen if, instead of using
QueueValue to accumulate results, we used AccumulateValue instead...
This would still pay the overhead of having (CountOf) allocate a new
FloatValue. ... Hmm. Passing around std::vector<double> would not
improve anything.

Added dot-fake to measure the query-only performance, discarding all of
the results (i.e. not doing any math.) Clearly, most of the CPU time is
spent in the pattern engine. Although the time lost in the Implicator,
and in the more complex patterns is significant, its not enough to focus
any further efforts on. So the concerns about `CountOf` and malloc of
`FloatValue` are minor: they add about 5% to the overall performance
(comparing `dot-fake` and `dot-simple`.) So.. that is also interesting
and useful to know.
