# Cognitive Primitive Tensor Encoding Specification

## üß¨ Overview

This document specifies the tensor encoding architecture for cognitive primitives in the CogML framework. The system implements a 5-dimensional tensor structure for representing agent states and cognitive processes within hypergraph-based knowledge representations.

## üìê Tensor Signature Specification

### Core 5D Tensor Shape

```
Cognitive_Primitive_Tensor[5] = [modality, depth, context, salience_bins, autonomy_bins]
                              = [4, 3, 3, 100, 100]
```

### Dimensional Semantics

#### 1. Modality Dimension (4 categories)
- **Index 0: VISUAL** - Visual perception and imagery processing
- **Index 1: AUDITORY** - Auditory processing and sound analysis  
- **Index 2: TEXTUAL** - Language and text comprehension
- **Index 3: SYMBOLIC** - Abstract symbolic reasoning and logic

#### 2. Depth Dimension (3 levels)
- **Index 0: SURFACE** - Surface-level perception and immediate sensory input
- **Index 1: SEMANTIC** - Semantic meaning and conceptual understanding
- **Index 2: PRAGMATIC** - Pragmatic context and intentional understanding

#### 3. Context Dimension (3 scopes)
- **Index 0: LOCAL** - Local immediate context and spatial proximity
- **Index 1: GLOBAL** - Global system-wide context and knowledge
- **Index 2: TEMPORAL** - Temporal historical and predictive context

#### 4. Salience Bins (100 levels)
- **Range: [0.0, 1.0]** - Attention salience and importance weighting
- **Binning**: Continuous values discretized into 100 levels for tensor encoding
- **Interpretation**: Higher values indicate greater cognitive importance

#### 5. Autonomy Bins (100 levels)  
- **Range: [0.0, 1.0]** - Autonomy index and self-direction capability
- **Binning**: Continuous values discretized into 100 levels for tensor encoding
- **Interpretation**: Higher values indicate greater autonomous decision-making capacity

## üî¢ Prime Factorization Mapping

### Mathematical Foundation

The tensor signature utilizes prime factorization for efficient indexing and retrieval:

```python
composite = (modality + 1) * 2 + (depth + 1) * 3 + (context + 1) * 5
prime_factors = factorize(composite)
```

### Example Mappings

| Modality | Depth | Context | Composite | Prime Factors |
|----------|-------|---------|-----------|---------------|
| VISUAL(0) | SURFACE(0) | LOCAL(0) | 11 | [11] |
| TEXTUAL(2) | SEMANTIC(1) | GLOBAL(1) | 22 | [2, 11] |
| SYMBOLIC(3) | PRAGMATIC(2) | TEMPORAL(2) | 25 | [5, 5] |

### Benefits
- **Fast Lookup**: O(log n) retrieval using prime-based indexing
- **Collision-Free**: Unique factorization ensures no hash collisions
- **Compact Storage**: Efficient memory representation for sparse tensors

## üéØ Degrees of Freedom (DOF) Analysis

### DOF Computation Formula

```python
base_dof = np.prod(tensor.shape)  # 4 * 3 * 3 * 100 * 100 = 360,000
constraints = 2  # salience and autonomy range constraints
effective_dof = min(base_dof - constraints, non_zero_elements)
```

### DOF Categories by Usage Pattern

#### Sparse Tensors (< 1% density)
- **Typical DOF**: 100-1,000
- **Use Case**: Single-modality focused primitives
- **Memory**: ~1KB per tensor

#### Medium Tensors (1-10% density)  
- **Typical DOF**: 1,000-36,000
- **Use Case**: Multi-modal cognitive states
- **Memory**: ~10-100KB per tensor

#### Dense Tensors (> 10% density)
- **Typical DOF**: 36,000-360,000
- **Use Case**: Complex system-wide representations
- **Memory**: >100KB per tensor

## üîó Hypergraph Encoding Patterns

### Node Encoding

Cognitive primitive tensors are encoded as AtomSpace nodes with tensor metadata:

```scheme
(ConceptNode "cognitive_primitive_1" 
    (stv salience autonomy_index)
    (EvaluationLink
        (PredicateNode "hasModality")
        (ListLink 
            (ConceptNode "cognitive_primitive_1")
            (ConceptNode "VisualModality")))
    (EvaluationLink
        (PredicateNode "hasDepth") 
        (ListLink
            (ConceptNode "cognitive_primitive_1")
            (ConceptNode "SemanticDepth")))
    (EvaluationLink
        (PredicateNode "hasContext")
        (ListLink
            (ConceptNode "cognitive_primitive_1") 
            (ConceptNode "GlobalContext"))))
```

### Link Encoding

Relationships between primitives are encoded as weighted links:

```scheme
(EvaluationLink (stv strength confidence)
    (PredicateNode "influences")
    (ListLink
        (ConceptNode "primitive_1")
        (ConceptNode "primitive_2")))
```

### Agent State Encoding

Agent cognitive states are represented as collections of primitive tensors:

```scheme
(EvaluationLink
    (PredicateNode "has_state")
    (ListLink
        (ConceptNode "agent_1")
        (ConceptNode "cognitive_primitive_1")))
```

## üîÑ Round-Trip Translation Protocol

### Forward Translation (Tensor ‚Üí Scheme)

1. **Extract Signature**: Parse tensor signature for modality, depth, context
2. **Generate Node**: Create ConceptNode with appropriate type
3. **Add Metadata**: Attach tensor metadata as EvaluationLinks
4. **Set Truth Values**: Encode salience/autonomy as strength/confidence

### Reverse Translation (Scheme ‚Üí Tensor)

1. **Parse Node**: Extract node ID and type from Scheme code
2. **Extract Metadata**: Parse EvaluationLinks for tensor attributes
3. **Reconstruct Signature**: Rebuild TensorSignature from metadata
4. **Create Tensor**: Instantiate CognitivePrimitiveTensor with signature

### Accuracy Validation

```python
def validate_round_trip(tensor, node_id):
    # Forward translation
    scheme_code = translator.tensor_to_scheme(tensor, node_id)
    
    # Reverse translation  
    reconstructed = translator.scheme_to_tensor(scheme_code)
    
    # Validate preservation
    return (tensor.signature.modality == reconstructed.signature.modality and
            tensor.signature.depth == reconstructed.signature.depth and  
            tensor.signature.context == reconstructed.signature.context and
            abs(tensor.signature.salience - reconstructed.signature.salience) < 1e-6 and
            abs(tensor.signature.autonomy_index - reconstructed.signature.autonomy_index) < 1e-6)
```

## üé® Visualization Framework

### Hypergraph Fragment Flowcharts

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Agent State    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Cognitive       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Hypergraph     ‚îÇ
‚îÇ  Tensors        ‚îÇ     ‚îÇ Primitive       ‚îÇ     ‚îÇ  Pattern        ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ Encoding        ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ [M,D,C,S,A]     ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ AtomSpace       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ                        ‚îÇ
         ‚ñº                        ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tensor          ‚îÇ     ‚îÇ Scheme          ‚îÇ     ‚îÇ Query &         ‚îÇ
‚îÇ Validation      ‚îÇ     ‚îÇ Translation     ‚îÇ     ‚îÇ Reasoning       ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ Structure ‚úì     ‚îÇ     ‚îÇ Round-trip ‚úì    ‚îÇ     ‚îÇ PLN Logic       ‚îÇ
‚îÇ Operations ‚úì    ‚îÇ     ‚îÇ Accuracy 95%+   ‚îÇ     ‚îÇ Pattern Match   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tensor Visualization Components

1. **Dimensional Heatmaps**: Visualize tensor activation across dimensions
2. **Network Graphs**: Show relationships between cognitive primitives  
3. **Timeline Views**: Display temporal evolution of cognitive states
4. **Attention Maps**: Visualize salience distribution across modalities

## üìä Performance Characteristics

### Encoding Performance

| Operation | Time Complexity | Space Complexity | Benchmark |
|-----------|----------------|------------------|-----------|
| Tensor Creation | O(1) | O(k) where k=tensor_size | ~0.001s |
| Scheme Translation | O(n) where n=attributes | O(n) | ~0.002s |
| Round-trip Validation | O(n) | O(n) | ~0.003s |
| Hypergraph Encoding | O(m) where m=tensors | O(m*n) | ~0.01s/tensor |

### Memory Usage Patterns

| Tensor Density | Memory/Tensor | Typical Use Case |
|----------------|---------------|------------------|
| Sparse (< 1%) | 1-10 KB | Single modality primitives |
| Medium (1-10%) | 10-100 KB | Multi-modal states |
| Dense (> 10%) | 100KB-1MB | System-wide representations |

### Scalability Metrics

- **Tensors/Second**: 1000+ tensor creations per second
- **Translation Rate**: 500+ round-trip translations per second  
- **Memory Efficiency**: 95%+ compression for sparse tensors
- **Accuracy Rate**: 99.9%+ round-trip translation accuracy

## üîß Implementation Guidelines

### Creating Cognitive Primitives

```python
from cogml import create_primitive_tensor, ModalityType, DepthType, ContextType

# Create visual perception primitive
visual_primitive = create_primitive_tensor(
    modality=ModalityType.VISUAL,
    depth=DepthType.SURFACE,
    context=ContextType.LOCAL,
    salience=0.8,
    autonomy_index=0.3,
    semantic_tags=["perception", "visual", "immediate"]
)
```

### Encoding Agent States

```python
from cogml import HypergraphEncoder

encoder = HypergraphEncoder()

# Multi-agent system
agents = {
    "visual_agent": [visual_primitive, auditory_primitive],
    "reasoning_agent": [symbolic_primitive, textual_primitive]
}

# Encode to AtomSpace
system_scheme = encoder.encode_cognitive_system(agents)
```

### Validation and Testing

```python
from cogml import run_comprehensive_validation

# Run full validation suite
results = run_comprehensive_validation()

# Check results
for test_name, result in results.items():
    print(f"{test_name}: {'PASS' if result.passed else 'FAIL'}")
```

## üöÄ Future Extensions

### Planned Enhancements

1. **Dynamic Tensor Shapes**: Support for variable-size tensors
2. **Hierarchical Encoding**: Multi-level tensor decomposition
3. **Temporal Sequences**: Time-series tensor representations
4. **Cross-Modal Fusion**: Advanced multi-modal integration patterns

### Research Directions

1. **Quantum Tensor Encoding**: Quantum-inspired tensor representations
2. **Neuromorphic Integration**: Hardware-optimized tensor processing
3. **Distributed Cognition**: Multi-node tensor synchronization
4. **Emergent Pattern Detection**: Automatic cognitive pattern discovery

## üìö References

1. OpenCog Hyperon Documentation
2. AtomSpace Hypergraph Specification  
3. Cognitive Architecture Design Patterns
4. Neural-Symbolic Integration Methodologies

---

*This specification document is part of Phase 1: Cognitive Primitives & Foundational Hypergraph Encoding for the CogML project.*